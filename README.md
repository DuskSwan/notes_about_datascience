[toc]

# 说明

1. 笔记为个人学习记录，内容来自网页、书籍、文档等。记录了各种数据科学相关的概念与模型、算法，包括它们的假设、核心思路、性质、计算方法、应用场景等。由于并非一次写成，在框架结构上可能存在诸多问题，我会在记录的过程中不断调整。

1. 以下笔记不涉及学科讲解。默认读者拥有线性代数、概率论、数理统计的基本知识。

1. 代码部分，用到的库包括但不限于numpy，pandas，sklearn等。默认读者拥有Python的基本知识，以及了解这些库。深度学习部分一律使用pytorch，版本可能变化。

1. 文中的一些概念，会有多种称呼或者记法。这部分是因为不同的参考文献中，记法各不相同；部分是因为我为了便于理解、区分概念，擅作主张的起了、或者修改了一些名字与记法。




# 新目录

## 0、需要声明的东西

- [x] [通用概念阐释](./note/通用概念阐释.md)

## 1、数学内容

- [ ] 奇异值分解（旧文件未迁移）
- [x] [傅立叶变换](./note/傅立叶变换.md)
- [ ] 小波分析
- [ ] 凸优化
- [ ] 时间序列分析基础
- [x] [经验模态分解EMD及其衍生](./note/经验模态分解EMD及其衍生.md)
- [x] [常用损失函数](./note/常用损失函数.md)


## 2、数据处理通用方法

- [ ] 数据预处理 
  - 样本均衡处理：欠采样、过采样、用模型均衡（旧文件未迁移）
- [ ] 可视化图表
- [ ] 特征工程
- [x] [相关性&相似度分析](./note/相关性&相似度分析.md)
  - 相关性系数，相似度算法等等


## 3、机器学习通用方法

- [x] [模型集成与提升](./note/模型集成与提升.md)
- [x] [模型选择与评估](./note/模型选择与评估.md)

## 4、统计与传统机器学习

- [ ] 线性回归与其衍生（旧文件未迁移）
- [ ] Logstic回归
- [x] [贝叶斯相关方法](./note/贝叶斯分类.md)
- [x] [支持向量机SVM及其扩展](./note/支持向量机SVM及其扩展.md)
- [x] [决策树与随机森林](./note/决策树与其集成.md)
- [ ] 最近邻法（旧文件未迁移）
- [x] [主成分分析PCA](./note/主成分分析PCA.md)
- [x] [因子分析](./note/因子分析.md)

## 5、深度学习的基本单元

- [x] [神经网络的基本概念](./note/神经网络的基本概念.md)
- [ ] 多层感知机（旧文件未迁移）
- [x] [卷积神经网络CNN及扩展](卷积神经网络CNN及扩展./note/.md)
- [x] [RNN与LSTM等](./note/RNN与LSTM等.md)
- [x] [自编码器AE及其扩展](./note/自编码器AE及其扩展.md)
- [x] [常用激活函数](./note/常用激活函数.md)
- [x] [优化器](./note/优化器.md)
- [x] [神经网络训练的技巧](./note/神经网络训练的技巧.md)
  - dropout，残差连接，正则化


## 6、针对各种目标的复杂网络

- [x] [Hopfield网络](./note/Hopfield网络.md)（比较粗略）

- [x] [R-CNN系网络](./note/R-CNN系网络.md)
- [x] [ViT图像分类](./note/ViT图像分类.md)

- [x] [Attention&Transformer](./note/Attention&Transformer.md)
- [x] [BERT](./note/BERT.md)
- [x] [ChatGPT](./note/ChatGPT.md)

- [x] [生成对抗网络GANs](./note/生成对抗网络GANs.md)
- [x] [去噪概率扩散模型DDPM](./note/去噪概率扩散模型DDPM.md)

- [x] [图神经网络GNN](./note/图神经网络GNN.md)

## 7、广泛的学习

- [ ] 迁移学习
- [ ] 元学习（泛泛而谈）
- [ ] 持续学习（旧文件未迁移）
- [x] [强化学习](./note/强化学习.md)
- [ ] 增量学习iCaRL（只记录了参考来源）


# 旧目录

一、数据分析的基本概念

二、数据感知与预处理方法

三、模型参数选择与评价

四、有监督学习-分类问题

五、有监督学习-回归问题

六、无监督学习-聚类问题

七、无监督学习-降维问题

八、深度学习与神经网络方法

九、假设检验方法

十、时间序列模型

十一、一些数学理论

十二、更多学习理论